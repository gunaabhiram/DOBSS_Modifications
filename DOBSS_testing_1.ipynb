{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKbOB7nB7tyk"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fi_KiXt7s2q"
      },
      "outputs": [],
      "source": [
        "import cvxpy as cp\n",
        "import numpy as np\n",
        "import random\n",
        "from scipy.optimize import linprog\n",
        "from tqdm import tqdm\n",
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def printf(s):\n",
        "  s = '\\n\\033[43m'+ '\\033[1m' + str(s) + '\\033[0m \\n'\n",
        "  print(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4lhIBpNC7Br"
      },
      "source": [
        "# Random Test case generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0gPDJ4IDAww"
      },
      "outputs": [],
      "source": [
        "def create(m,n):\n",
        "\n",
        "  if type(n) is int:\n",
        "    n = [n]\n",
        "\n",
        "  R = []; C = []\n",
        "  for i in range(len(n)):\n",
        "    R.append(np.random.randint(100,size=(m,n[i])))\n",
        "    C.append(np.random.randint(100,size=(m,n[i])))\n",
        "  \n",
        "  p = [1/len(n)]*len(n)\n",
        "  return R,C,p\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZM_u8ZU70-y"
      },
      "source": [
        "# DOBSS and DOBSS modification 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOqaihss78Fm"
      },
      "outputs": [],
      "source": [
        "# Stackelberg game solution -> without change\n",
        "def formulate_sg(R,C,p,M=1e3,Δ=0,lp=0):\n",
        "\n",
        "  m,n = R.shape\n",
        "\n",
        "  z = cp.Variable((m,n), nonneg=True)\n",
        "  q = cp.Variable(n,integer=True)\n",
        "  a = cp.Variable(1)\n",
        "\n",
        "  obj = p*cp.Maximize(sum(sum(cp.multiply(R,z))))\n",
        "  con = [#z<=1,q<=1, #feasibility, but this is implied by the following constraints\n",
        "         \n",
        "         0<=q,\n",
        "         sum(sum(z))==1, #sum of all xi's=1 -> belongs to probability simplex\n",
        "         sum(z.T)<=1, #individual xi's <=1 -> belongs to probability simplex\n",
        "\n",
        "         q<=sum(z), sum(z)<=1, #as zij=xi.qj\n",
        "         sum(q)==1, #sum of all qj's=1 -> belongs to probability simplex\n",
        "\n",
        "         0<=a-sum(z.T)@C, a-sum(z.T)@C-M*(1-q)<=0, #follower's problem -> maximizing follower revenue\n",
        "\n",
        "       ]\n",
        "\n",
        "  if lp==1:\n",
        "    x = cp.Variable(m,integer=True)\n",
        "    con+=[sum(z.T)==x]\n",
        "\n",
        "  return obj, con, z, q\n",
        "\n",
        "\n",
        "# Stackelberg game solution \n",
        "def formulate_sg2(R,C,p,M=1e3,Δ=0,lp=0):\n",
        "\n",
        "  m,n = R.shape\n",
        "\n",
        "  z = cp.Variable((m,n), nonneg=True)\n",
        "  q = cp.Variable(n,integer=True)\n",
        "  a = cp.Variable(1)\n",
        "\n",
        "  obj = p*cp.Maximize(sum(sum(cp.multiply(R,z))))\n",
        "  con = [\n",
        "         \n",
        "        #  z<=1,q<=1, #feasibility, but this is implied by the following constraints\n",
        "         0<=q,\n",
        "         sum(sum(z))==1, #sum of all xi's=1 -> belongs to probability simplex\n",
        "         sum(z.T)<=1, #individual xi's <=1 -> belongs to probability simplex\n",
        "\n",
        "         q<=sum(z), sum(z)<=1, #as zij=xi.qj\n",
        "         sum(q)==1, #sum of all qj's=1 -> belongs to probability simplex\n",
        "\n",
        "        #  x == sum(z.T), # by definition\n",
        "        #  0<=a-x@C, a-x@C-1e3*(1-q)<=0, #follower's problem -> maximizing follower revenue\n",
        "         0<=a-sum(z.T)@C, a-sum(z.T)@C-M*(1-q)<=0, #follower's problem -> maximizing follower revenue\n",
        "         sum(sum(cp.multiply(R,z))) <= Δ + sum(z.T)@R + M*( sum(sum(cp.multiply(C,z))) - sum(z.T)@C ) # Select the payoff of leader which minimum among all available maximizing strategies of follower\n",
        "       ]\n",
        "\n",
        "  if lp==1:\n",
        "    x = cp.Variable(m,integer=True)\n",
        "    con+=[sum(z.T)==x]\n",
        "\n",
        "  return obj, con, z, q\n",
        "\n",
        "\n",
        "# Bayesian Stackelberg game solution \n",
        "def formulate_bsg(R,C,p,solver=1,Δ=0,lp=0):\n",
        "\n",
        "  for l in range(len(R)):\n",
        "    if solver==0:\n",
        "      o,c,z,q = formulate_sg(R[l],C[l],p[l],Δ=Δ,lp=lp)\n",
        "    elif solver==1:\n",
        "      o,c,z,q = formulate_sg2(R[l],C[l],p[l],Δ=Δ,lp=lp)\n",
        "\n",
        "    if l == 0:\n",
        "      Obj = o\n",
        "      Con = c\n",
        "      Z = [z]\n",
        "      Q = [q]\n",
        "    else:\n",
        "      Obj += o\n",
        "      Con += c\n",
        "      Z +=[z]\n",
        "      Q +=[q]\n",
        "\n",
        "  return Obj,Con,Z,Q \n",
        "\n",
        "\n",
        "# Solver of the game \n",
        "def optimal_strategy(R,C,p,show=False,solver=0,Δ=0,lp=0):\n",
        "\n",
        "  obj, con, Z, Q = formulate_bsg(R,C,p,solver=solver,Δ=Δ,lp=lp)\n",
        "\n",
        "  if len(Z)>1:\n",
        "    c2 = []\n",
        "    for l in range(len(Z)):\n",
        "      if l==0:\n",
        "        k = sum(Z[l].T)\n",
        "      else:\n",
        "        c2+=[k==sum(Z[l].T)] # additional constraint for all xi's to be equal    \n",
        "    con+=c2\n",
        "\n",
        "  prob = cp.Problem(obj, con)\n",
        "  # The optimal objective value is returned by `prob.solve()`.\n",
        "  result = prob.solve()\n",
        "\n",
        "  for i in range(len(Z)):\n",
        "    if i == 0:\n",
        "      zf = np.sum(np.asarray(Z[i].value),axis=1)/len(Z)\n",
        "    else:\n",
        "      zf += np.sum(np.asarray(Z[i].value),axis=1)/len(Z)\n",
        "\n",
        "\n",
        "  ans = 0\n",
        "  ans2 = 0\n",
        "  for i in range(len(Z)):\n",
        "    ans += np.sum(Z[i].value*R[i])*p[i]\n",
        "    ans2 += np.sum(Z[i].value*C[i])*p[i]\n",
        "\n",
        "\n",
        "  if show==True:\n",
        "\n",
        "    print(\"-------------------------------------------------\")\n",
        "    printf('Solver='+str(solver)+'  Δ='+str(Δ))\n",
        "    print(\"Optimal value: \",prob.value,'\\n\\n')\n",
        "    print(\"Leader\\'s strategy\",'\\n',zf,'\\n\\n')\n",
        "    print(\"Follower strategies - for different types\")\n",
        "    for i in range(len(Z)):\n",
        "      print(\"Player type\",i,\" : \", Q[i].value)\n",
        "    print('\\n')\n",
        "    print(\"-------------------------------------------------\")\n",
        "\n",
        "  return ans, ans2, Z # strategy profile\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHQdUj5uyFJ9",
        "outputId": "fe119792-6307-4aae-de42-cf57bc6ecec4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[2. , 1. ],\n",
            "       [4. , 1.9]])]\n",
            "[array([[2, 2],\n",
            "       [3, 3]])]\n"
          ]
        }
      ],
      "source": [
        "R = [np.asarray ( [[2,1],[4,1.9]] ) ]\n",
        "print(R)\n",
        "\n",
        "C = [np.asarray(  [[2,2],[3,3]] ) ]\n",
        "print(C)\n",
        "\n",
        "p = [1]\n",
        "\n",
        "v,f,Z = optimal_strategy(R,C,p,show=False,solver=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCTM7MIf8NZJ"
      },
      "source": [
        "# DOBSS modification 2,3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOQNhMJI8PY8"
      },
      "outputs": [],
      "source": [
        "def formulate_sg_ir2(R,C,p,K=1/2,L=10,frac=0.10,solver=0,lp=0):\n",
        "\n",
        "  m,n = R.shape\n",
        "  # M = max(np.max(abs(R)),np.max(abs(C)))+1e3\n",
        "  M=1e3\n",
        "\n",
        "  K2=1\n",
        "  if K<=1:\n",
        "    K2=0\n",
        "    K=1\n",
        "\n",
        "  z = cp.Variable((m,n), nonneg=True)\n",
        "  w = cp.Variable((m,n), nonneg=True)\n",
        "  q = cp.Variable(n,integer=True)\n",
        "  r = cp.Variable(n,integer=True)\n",
        "  g = cp.Variable(n,integer=True) \n",
        "  a = cp.Variable(1)\n",
        "\n",
        "  con = []\n",
        "\n",
        "  if solver!=0:\n",
        "    L = cp.Variable(1)\n",
        "    con+=[L==a*frac]\n",
        "\n",
        "  obj = p*cp.Maximize(sum(sum(cp.multiply(R,w))))\n",
        "  con +=[\n",
        "         # Constraints from DOBSS\n",
        "         sum(sum(z))==1,                                                                                     # Sum of all xi's=1     -> belongs to probability simplex\n",
        "         sum(z.T)<=1,                                                                                        # Individual xi's <=1   -> belongs to probability simplex\n",
        "         0<=q, sum(q)==1,                                                                                    # Sum of all qj's=1     -> belongs to probability simplex\n",
        "         q<=sum(z), sum(z)<=1,                                                                               # As zij=xi.qj          -> definition of zij's\n",
        "         0<=a-sum(z.T)@C, a-sum(z.T)@C-M*(1-q)<=0,                                                           #           a           -> Max follower payoff for given leader strategy\n",
        "\n",
        "         # Constraints for modelling Irrational behaviour         \n",
        "         g<=1, 0<=g,                                                                                         # Truth value variables -> binary\n",
        "         sum(z.T) == sum(w.T),                                                                               # As wij=xi.q'j         -> definition of wij's\n",
        "         r<=sum(w),\n",
        "         0<=r, sum(r)==1,\n",
        "         K2*(sum(sum(cp.multiply(C,w))) - sum(w.T)@C) >= (sum(sum(cp.multiply(R,w))) - sum(w.T)@R)/K - M*g,  # Comparisions          -> the loss of follower < k*(loss of leader) \n",
        "         a - sum(sum(cp.multiply(C,w))) <= L,                                                                # Stop loss condition   -> the loss of follower <= stop loss\n",
        "         a - sum(w.T)@C >= L - M*(1-g),                                                                      # Stop loss criterion   -> truth value from g \n",
        "         a - sum(w.T)@C <= L + M*g                                                                           # Stop loss criterion   -> truth value from g \n",
        "       ]\n",
        "\n",
        "\n",
        "  if lp==1:\n",
        "    x = cp.Variable(m,integer=True)\n",
        "    con+=[sum(z.T)==x]\n",
        "    con+=[sum(w.T)==x]\n",
        "\n",
        "  return obj, con, w, z, q, g, a, r\n",
        "\n",
        "\n",
        "\n",
        "# Bayesian Stackelberg game solution \n",
        "def formulate_bsg2(R,C,p,solver=0,K=2,L=10,frac=0.1,lp=0):\n",
        "\n",
        "  for l in range(len(R)):\n",
        "\n",
        "    o, c, w, z, q, g, a, r = formulate_sg_ir2(R[l],C[l],p[l],K=K,L=L,solver=solver,frac=frac,lp=lp)    \n",
        "\n",
        "    if l == 0:\n",
        "      Obj = o\n",
        "      Con = c\n",
        "      W = [w]\n",
        "      Z = [z]\n",
        "      Q = [q]\n",
        "      G = [g]\n",
        "      A = [a]\n",
        "      Rr = [r]\n",
        "\n",
        "    else:\n",
        "      Obj += o\n",
        "      Con += c\n",
        "      W += [w]\n",
        "      Z += [z]\n",
        "      Q += [q]\n",
        "      G += [g]\n",
        "      A += [a]\n",
        "      Rr += [r]\n",
        "\n",
        "  return Obj,Con,W,Z,Q,G,A,Rr\n",
        "\n",
        "\n",
        "def optimal_strategy2(R,C,p,show=False,K=2,L=10,solver=0,frac=0,lp=0):\n",
        "\n",
        "  Obj,Con,W,Z,Q,G,A,Rr = formulate_bsg2(R,C,p,K=K,L=L,solver=solver,frac=frac,lp=lp)\n",
        "\n",
        "  if len(W)>1:\n",
        "    c2 = []\n",
        "    for l in range(len(W)):\n",
        "      if l==0:\n",
        "        k = sum(W[l].T)\n",
        "      else:\n",
        "        c2+=[k==sum(W[l].T)] # additional constraint for all xi's to be equal    \n",
        "    Con+=c2\n",
        "\n",
        "  prob = cp.Problem(Obj,Con)\n",
        "  result = prob.solve()\n",
        "\n",
        "  ans = 0\n",
        "  ans2 = 0\n",
        "  for i in range(len(W)):\n",
        "    ans += np.sum(W[i].value*R[i])*p[i]\n",
        "    ans2 += np.sum(W[i].value*C[i])*p[i]\n",
        "\n",
        "  for i in range(len(W)):\n",
        "    if i == 0:\n",
        "      wf = np.sum(np.asarray(W[i].value),axis=1)\n",
        "    else:\n",
        "      wf += np.sum(np.asarray(W[i].value),axis=1)\n",
        "  wf = wf/len(W)\n",
        "\n",
        "\n",
        "  if show == True:\n",
        "\n",
        "    if solver == 0:\n",
        "      printf('Solver='+str(solver+3)+'  K-factor='+str(K) +';  Stop loss ='+str(L))\n",
        "    else:\n",
        "      printf('Solver='+str(solver+3)+'  K-factor='+str(K) +';  Fractional loss ='+str(frac))\n",
        "\n",
        "    print(\"-------------------------------------------------\")\n",
        "    print(\"Objective value \"+str(ans))\n",
        "\n",
        "    print(\"-------------------------------------------------\")\n",
        "    print(\"W\")\n",
        "    for i in range(len(W)):\n",
        "      print(\"player type \",i+1)\n",
        "      print(W[i].value)\n",
        "\n",
        "    print(\"-------------------------------------------------\")\n",
        "    print(\"Z\")\n",
        "    for i in range(len(Z)):\n",
        "      print(\"player type \",i+1)\n",
        "      print(Z[i].value)\n",
        "    \n",
        "    print(\"-------------------------------------------------\")\n",
        "    print(\"Q\")\n",
        "    for i in range(len(Q)):\n",
        "      print(\"player type \",i+1)\n",
        "      print(Q[i].value)\n",
        "\n",
        "    print(\"-------------------------------------------------\")\n",
        "    print(\"G\")\n",
        "    for i in range(len(G)):\n",
        "      print(\"player type \",i+1)\n",
        "      print(G[i].value)\n",
        "    \n",
        "    print(\"-------------------------------------------------\")\n",
        "    print(\"A\")\n",
        "    for i in range(len(A)):\n",
        "      print(\"player type \",i+1)\n",
        "      print(A[i].value)\n",
        "\n",
        "    print(\"-------------------------------------------------\")\n",
        "    print(\"Rr\")\n",
        "    for i in range(len(Rr)):\n",
        "      print(\"player type \",i+1)\n",
        "      print(Rr[i].value)\n",
        "\n",
        "    print(\"-------------------------------------------------\")\n",
        "\n",
        "    print(\"Leader payoff: \",ans,'\\n\\n')\n",
        "    \n",
        "    print(\"Follower payoff - for different types\")\n",
        "    for i in range(len(W)):\n",
        "      print(\"Player type\",i,\" : \", np.sum(W[i].value*C[i]))\n",
        "    print('\\n')\n",
        "\n",
        "    print(\"-------------------------------------------------\")\n",
        "\n",
        "    print(\"Leader\\'s strategy\",'\\n',wf,'\\n\\n')\n",
        "\n",
        "    print(\"Follower strategies - for different types\")\n",
        "    L2 = []\n",
        "    for i in range(len(W)):\n",
        "      print(\"Player type\",i,\" : \", np.sum(np.asarray(W[i].value),axis=0))\n",
        "      L2.append(np.sum(np.asarray(W[i].value),axis=0))\n",
        "    print('\\n')\n",
        "    \n",
        "    for i in range(len(W)):\n",
        "      print(\"W matrix\",i,\" : \", np.asarray(W[i].value))\n",
        "    print('\\n')\n",
        "\n",
        "    print(\"-------------------------------------------------\")\n",
        "\n",
        "\n",
        "  return ans, ans2, W \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMEapV9l8hYP"
      },
      "source": [
        "# Comparing solutions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0NpgamRl0gE"
      },
      "source": [
        "# 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJPZ2oxSM7KR"
      },
      "source": [
        "Let us understand how the follower picks his/her strategy and how is it different from the original algorithm using the simple example of the leader having a single strategy.\n",
        "\n",
        "The leader has no choice of strategies here. And the follower can choose an appropriate strategy according to his/her parameter choices (L,K)\n",
        "\n",
        "The same concept can be extended to cases when the leader has multiple pure strategies, and also he is able to select mixed strategies.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4u8u6JmBgZq",
        "outputId": "7d69a6a8-abaa-4ebf-f90c-7248662159d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[5. , 4.5, 3. , 0. , 6. ]])]\n",
            "[array([[5. , 5. , 4.5, 4. , 4.5]])]\n",
            "-------------------------------------------------\n",
            "\n",
            "\u001b[43m\u001b[1mSolver=0  Δ=0\u001b[0m \n",
            "\n",
            "Optimal value:  5.0 \n",
            "\n",
            "\n",
            "Leader's strategy \n",
            " [1.] \n",
            "\n",
            "\n",
            "Follower strategies - for different types\n",
            "Player type 0  :  [1. 0. 0. 0. 0.]\n",
            "\n",
            "\n",
            "-------------------------------------------------\n",
            "XXX---------------XXX---------------XXX---------------XXX\n",
            "\n",
            "\n",
            "\n",
            "-------------------------------------------------\n",
            "\n",
            "\u001b[43m\u001b[1mSolver=1  Δ=0\u001b[0m \n",
            "\n",
            "Optimal value:  4.5 \n",
            "\n",
            "\n",
            "Leader's strategy \n",
            " [1.] \n",
            "\n",
            "\n",
            "Follower strategies - for different types\n",
            "Player type 0  :  [0. 1. 0. 0. 0.]\n",
            "\n",
            "\n",
            "-------------------------------------------------\n",
            "XXX---------------XXX---------------XXX---------------XXX\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[43m\u001b[1mSolver=3  K-factor=4;  Stop loss =2\u001b[0m \n",
            "\n",
            "-------------------------------------------------\n",
            "Objective value 0.0\n",
            "-------------------------------------------------\n",
            "W\n",
            "player type  1\n",
            "[[0. 0. 0. 1. 0.]]\n",
            "-------------------------------------------------\n",
            "Z\n",
            "player type  1\n",
            "[[1. 0. 0. 0. 0.]]\n",
            "-------------------------------------------------\n",
            "Q\n",
            "player type  1\n",
            "[1. 0. 0. 0. 0.]\n",
            "-------------------------------------------------\n",
            "G\n",
            "player type  1\n",
            "[0. 0. 0. 0. 0.]\n",
            "-------------------------------------------------\n",
            "A\n",
            "player type  1\n",
            "[5.]\n",
            "-------------------------------------------------\n",
            "Rr\n",
            "player type  1\n",
            "[0. 0. 0. 1. 0.]\n",
            "-------------------------------------------------\n",
            "Leader payoff:  0.0 \n",
            "\n",
            "\n",
            "Follower payoff - for different types\n",
            "Player type 0  :  4.0\n",
            "\n",
            "\n",
            "-------------------------------------------------\n",
            "Leader's strategy \n",
            " [1.] \n",
            "\n",
            "\n",
            "Follower strategies - for different types\n",
            "Player type 0  :  [0. 0. 0. 1. 0.]\n",
            "\n",
            "\n",
            "W matrix 0  :  [[0. 0. 0. 1. 0.]]\n",
            "\n",
            "\n",
            "-------------------------------------------------\n",
            "XXX---------------XXX---------------XXX---------------XXX\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[43m\u001b[1mSolver=3  K-factor=4.4;  Stop loss =1.1\u001b[0m \n",
            "\n",
            "-------------------------------------------------\n",
            "Objective value 0.0\n",
            "-------------------------------------------------\n",
            "W\n",
            "player type  1\n",
            "[[0. 0. 0. 1. 0.]]\n",
            "-------------------------------------------------\n",
            "Z\n",
            "player type  1\n",
            "[[1. 0. 0. 0. 0.]]\n",
            "-------------------------------------------------\n",
            "Q\n",
            "player type  1\n",
            "[1. 0. 0. 0. 0.]\n",
            "-------------------------------------------------\n",
            "G\n",
            "player type  1\n",
            "[0. 0. 0. 0. 0.]\n",
            "-------------------------------------------------\n",
            "A\n",
            "player type  1\n",
            "[5.]\n",
            "-------------------------------------------------\n",
            "Rr\n",
            "player type  1\n",
            "[0. 0. 0. 1. 0.]\n",
            "-------------------------------------------------\n",
            "Leader payoff:  0.0 \n",
            "\n",
            "\n",
            "Follower payoff - for different types\n",
            "Player type 0  :  4.0\n",
            "\n",
            "\n",
            "-------------------------------------------------\n",
            "Leader's strategy \n",
            " [1.] \n",
            "\n",
            "\n",
            "Follower strategies - for different types\n",
            "Player type 0  :  [0. 0. 0. 1. 0.]\n",
            "\n",
            "\n",
            "W matrix 0  :  [[0. 0. 0. 1. 0.]]\n",
            "\n",
            "\n",
            "-------------------------------------------------\n",
            "XXX---------------XXX---------------XXX---------------XXX\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[43m\u001b[1mSolver=3  K-factor=4.49;  Stop loss =1.01\u001b[0m \n",
            "\n",
            "-------------------------------------------------\n",
            "Objective value 0.0\n",
            "-------------------------------------------------\n",
            "W\n",
            "player type  1\n",
            "[[0. 0. 0. 1. 0.]]\n",
            "-------------------------------------------------\n",
            "Z\n",
            "player type  1\n",
            "[[1. 0. 0. 0. 0.]]\n",
            "-------------------------------------------------\n",
            "Q\n",
            "player type  1\n",
            "[1. 0. 0. 0. 0.]\n",
            "-------------------------------------------------\n",
            "G\n",
            "player type  1\n",
            "[0. 0. 0. 0. 0.]\n",
            "-------------------------------------------------\n",
            "A\n",
            "player type  1\n",
            "[5.]\n",
            "-------------------------------------------------\n",
            "Rr\n",
            "player type  1\n",
            "[0. 0. 0. 1. 0.]\n",
            "-------------------------------------------------\n",
            "Leader payoff:  0.0 \n",
            "\n",
            "\n",
            "Follower payoff - for different types\n",
            "Player type 0  :  4.0\n",
            "\n",
            "\n",
            "-------------------------------------------------\n",
            "Leader's strategy \n",
            " [1.] \n",
            "\n",
            "\n",
            "Follower strategies - for different types\n",
            "Player type 0  :  [0. 0. 0. 1. 0.]\n",
            "\n",
            "\n",
            "W matrix 0  :  [[0. 0. 0. 1. 0.]]\n",
            "\n",
            "\n",
            "-------------------------------------------------\n",
            "XXX---------------XXX---------------XXX---------------XXX\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[43m\u001b[1mSolver=3  K-factor=4.6;  Stop loss =0.9\u001b[0m \n",
            "\n",
            "-------------------------------------------------\n",
            "Objective value 4.5\n",
            "-------------------------------------------------\n",
            "W\n",
            "player type  1\n",
            "[[0. 1. 0. 0. 0.]]\n",
            "-------------------------------------------------\n",
            "Z\n",
            "player type  1\n",
            "[[1. 0. 0. 0. 0.]]\n",
            "-------------------------------------------------\n",
            "Q\n",
            "player type  1\n",
            "[1. 0. 0. 0. 0.]\n",
            "-------------------------------------------------\n",
            "G\n",
            "player type  1\n",
            "[0. 0. 0. 1. 0.]\n",
            "-------------------------------------------------\n",
            "A\n",
            "player type  1\n",
            "[5.]\n",
            "-------------------------------------------------\n",
            "Rr\n",
            "player type  1\n",
            "[0. 1. 0. 0. 0.]\n",
            "-------------------------------------------------\n",
            "Leader payoff:  4.5 \n",
            "\n",
            "\n",
            "Follower payoff - for different types\n",
            "Player type 0  :  5.0\n",
            "\n",
            "\n",
            "-------------------------------------------------\n",
            "Leader's strategy \n",
            " [1.] \n",
            "\n",
            "\n",
            "Follower strategies - for different types\n",
            "Player type 0  :  [0. 1. 0. 0. 0.]\n",
            "\n",
            "\n",
            "W matrix 0  :  [[0. 1. 0. 0. 0.]]\n",
            "\n",
            "\n",
            "-------------------------------------------------\n",
            "XXX---------------XXX---------------XXX---------------XXX\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[43m\u001b[1mSolver=3  K-factor=6;  Stop loss =2\u001b[0m \n",
            "\n",
            "-------------------------------------------------\n",
            "Objective value 4.5\n",
            "-------------------------------------------------\n",
            "W\n",
            "player type  1\n",
            "[[0. 1. 0. 0. 0.]]\n",
            "-------------------------------------------------\n",
            "Z\n",
            "player type  1\n",
            "[[1. 0. 0. 0. 0.]]\n",
            "-------------------------------------------------\n",
            "Q\n",
            "player type  1\n",
            "[1. 0. 0. 0. 0.]\n",
            "-------------------------------------------------\n",
            "G\n",
            "player type  1\n",
            "[0. 0. 0. 0. 0.]\n",
            "-------------------------------------------------\n",
            "A\n",
            "player type  1\n",
            "[5.]\n",
            "-------------------------------------------------\n",
            "Rr\n",
            "player type  1\n",
            "[0. 1. 0. 0. 0.]\n",
            "-------------------------------------------------\n",
            "Leader payoff:  4.5 \n",
            "\n",
            "\n",
            "Follower payoff - for different types\n",
            "Player type 0  :  5.0\n",
            "\n",
            "\n",
            "-------------------------------------------------\n",
            "Leader's strategy \n",
            " [1.] \n",
            "\n",
            "\n",
            "Follower strategies - for different types\n",
            "Player type 0  :  [0. 1. 0. 0. 0.]\n",
            "\n",
            "\n",
            "W matrix 0  :  [[0. 1. 0. 0. 0.]]\n",
            "\n",
            "\n",
            "-------------------------------------------------\n",
            "XXX---------------XXX---------------XXX---------------XXX\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[43m\u001b[1mSolver=3  K-factor=4;  Stop loss =0.8\u001b[0m \n",
            "\n",
            "-------------------------------------------------\n",
            "Objective value 4.5\n",
            "-------------------------------------------------\n",
            "W\n",
            "player type  1\n",
            "[[0. 1. 0. 0. 0.]]\n",
            "-------------------------------------------------\n",
            "Z\n",
            "player type  1\n",
            "[[1. 0. 0. 0. 0.]]\n",
            "-------------------------------------------------\n",
            "Q\n",
            "player type  1\n",
            "[1. 0. 0. 0. 0.]\n",
            "-------------------------------------------------\n",
            "G\n",
            "player type  1\n",
            "[0. 0. 0. 1. 0.]\n",
            "-------------------------------------------------\n",
            "A\n",
            "player type  1\n",
            "[5.]\n",
            "-------------------------------------------------\n",
            "Rr\n",
            "player type  1\n",
            "[0. 1. 0. 0. 0.]\n",
            "-------------------------------------------------\n",
            "Leader payoff:  4.5 \n",
            "\n",
            "\n",
            "Follower payoff - for different types\n",
            "Player type 0  :  5.0\n",
            "\n",
            "\n",
            "-------------------------------------------------\n",
            "Leader's strategy \n",
            " [1.] \n",
            "\n",
            "\n",
            "Follower strategies - for different types\n",
            "Player type 0  :  [0. 1. 0. 0. 0.]\n",
            "\n",
            "\n",
            "W matrix 0  :  [[0. 1. 0. 0. 0.]]\n",
            "\n",
            "\n",
            "-------------------------------------------------\n",
            "XXX---------------XXX---------------XXX---------------XXX\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[43m\u001b[1mSolver=3  K-factor=-0.5;  Stop loss =0.5\u001b[0m \n",
            "\n",
            "-------------------------------------------------\n",
            "Objective value 4.5\n",
            "-------------------------------------------------\n",
            "W\n",
            "player type  1\n",
            "[[0. 1. 0. 0. 0.]]\n",
            "-------------------------------------------------\n",
            "Z\n",
            "player type  1\n",
            "[[1. 0. 0. 0. 0.]]\n",
            "-------------------------------------------------\n",
            "Q\n",
            "player type  1\n",
            "[1. 0. 0. 0. 0.]\n",
            "-------------------------------------------------\n",
            "G\n",
            "player type  1\n",
            "[0. 0. 1. 1. 0.]\n",
            "-------------------------------------------------\n",
            "A\n",
            "player type  1\n",
            "[5.]\n",
            "-------------------------------------------------\n",
            "Rr\n",
            "player type  1\n",
            "[0. 1. 0. 0. 0.]\n",
            "-------------------------------------------------\n",
            "Leader payoff:  4.5 \n",
            "\n",
            "\n",
            "Follower payoff - for different types\n",
            "Player type 0  :  5.0\n",
            "\n",
            "\n",
            "-------------------------------------------------\n",
            "Leader's strategy \n",
            " [1.] \n",
            "\n",
            "\n",
            "Follower strategies - for different types\n",
            "Player type 0  :  [0. 1. 0. 0. 0.]\n",
            "\n",
            "\n",
            "W matrix 0  :  [[0. 1. 0. 0. 0.]]\n",
            "\n",
            "\n",
            "-------------------------------------------------\n",
            "XXX---------------XXX---------------XXX---------------XXX\n",
            "\n",
            "\n",
            "\n",
            "------------------------------------------------------------------------------------------\n",
            "                                    Leader     | Follower  \n",
            "------------------------------------------------------------------------------------------\n",
            "Original DOBSS                      5.0        | 5.0       \n",
            "Mod-1 DOBSS                         4.5        | 5.0       \n",
            "------------------------------------------------------------------------------------------\n",
            "Mod-2 DOBSS,K=4,L=2                 0.0        | 4.0       \n",
            "Mod-2 DOBSS,K=4.4,L=1.1             0.0        | 4.0       \n",
            "Mod-2 DOBSS,K=4.49,L=1.01           0.0        | 4.0       \n",
            "Mod-2 DOBSS,K=4.6,L=0.9             4.5        | 5.0       \n",
            "Mod-2 DOBSS,K=6,L=2                 4.5        | 5.0       \n",
            "Mod-2 DOBSS,K=4,L=0.8               4.5        | 5.0       \n",
            "**Mod-2 DOBSS,K=-0.5,L=0.5          4.5        | 5.0       \n"
          ]
        }
      ],
      "source": [
        "R = [np.asarray ( [[5,4.5,3,0,6]] ) ]\n",
        "print(R)\n",
        "\n",
        "C = [np.asarray(  [[5,5,4.5,4,4.5]] ) ]\n",
        "print(C)\n",
        "\n",
        "p = [1]\n",
        "\n",
        "v,f,Z = optimal_strategy(R,C,p,show=True,solver=0)\n",
        "print(\"XXX---------------XXX---------------XXX---------------XXX\\n\\n\\n\")\n",
        "\n",
        "v0,f0,Z0 = optimal_strategy(R,C,p,show=True,solver=1,Δ=0)\n",
        "print(\"XXX---------------XXX---------------XXX---------------XXX\\n\\n\\n\")\n",
        "\n",
        "v1,f1,Z1 = optimal_strategy2(R,C,p,show=True,K=4,L=2,solver=0)\n",
        "print(\"XXX---------------XXX---------------XXX---------------XXX\\n\\n\\n\")\n",
        "\n",
        "v2,f2,Z2 = optimal_strategy2(R,C,p,show=True,K=4.4,L=1.1,solver=0)\n",
        "print(\"XXX---------------XXX---------------XXX---------------XXX\\n\\n\\n\")\n",
        "\n",
        "v3,f3,Z3 = optimal_strategy2(R,C,p,show=True,K=4.49,L=1.01,solver=0)\n",
        "print(\"XXX---------------XXX---------------XXX---------------XXX\\n\\n\\n\")\n",
        "\n",
        "v4,f4,Z4 = optimal_strategy2(R,C,p,show=True,K=4.6,L=0.9,solver=0)\n",
        "print(\"XXX---------------XXX---------------XXX---------------XXX\\n\\n\\n\")\n",
        "\n",
        "v5,f5,Z5 = optimal_strategy2(R,C,p,show=True,K=6,L=2,solver=0)\n",
        "print(\"XXX---------------XXX---------------XXX---------------XXX\\n\\n\\n\")\n",
        "\n",
        "v6,f6,Z6 = optimal_strategy2(R,C,p,show=True,K=4,L=0.8,solver=0)\n",
        "print(\"XXX---------------XXX---------------XXX---------------XXX\\n\\n\\n\")\n",
        "\n",
        "v7,f7,Z7 = optimal_strategy2(R,C,p,show=True,K=-0.5,L=0.5,solver=0)\n",
        "print(\"XXX---------------XXX---------------XXX---------------XXX\\n\\n\\n\")\n",
        "\n",
        "\n",
        "# v4,f4 = optimal_strategy2(R,C,p,show=True,K=2,frac=0.1,solver=1)\n",
        "# print(v1,'\\n',v2,'\\n',v3,'\\n',v4,'\\n')\n",
        "\n",
        "\n",
        "print(\"------------------------------------------------------------------------------------------\")\n",
        "\n",
        "print(  \"{:<35}\".format(\" \"), \"{:<10} {:1} {:<10}\".format(  \"Leader\",'|', \"Follower\"  ))\n",
        "print(\"------------------------------------------------------------------------------------------\")\n",
        "\n",
        "print( \"{:<35}\".format(\"Original DOBSS\") ,\"{:<10} {:1} {:<10}\".format(  round(v,2),'|',round(f,2)))\n",
        "print( \"{:<35}\".format(\"Mod-1 DOBSS\")    ,\"{:<10} {:1} {:<10}\".format(  round(v0,2),'|',round(f0,2)))\n",
        "\n",
        "print(\"------------------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "print( \"{:<35}\".format(\"Mod-2 DOBSS,K=4,L=2\")    ,\"{:<10} {:1} {:<10}\".format(  round(v1,2),'|',round(f1,2)))\n",
        "print( \"{:<35}\".format(\"Mod-2 DOBSS,K=4.4,L=1.1\")    ,\"{:<10} {:1} {:<10}\".format(  round(v2,2),'|',round(f2,2)))\n",
        "print( \"{:<35}\".format(\"Mod-2 DOBSS,K=4.49,L=1.01\")    ,\"{:<10} {:1} {:<10}\".format(  round(v3,2),'|',round(f3,2)))\n",
        "print( \"{:<35}\".format(\"Mod-2 DOBSS,K=4.6,L=0.9\")    ,\"{:<10} {:1} {:<10}\".format(  round(v4,2),'|',round(f4,2)))\n",
        "print( \"{:<35}\".format(\"Mod-2 DOBSS,K=6,L=2\")    ,\"{:<10} {:1} {:<10}\".format(  round(v5,2),'|',round(f5,2)))\n",
        "print( \"{:<35}\".format(\"Mod-2 DOBSS,K=4,L=0.8\")    ,\"{:<10} {:1} {:<10}\".format(  round(v6,2),'|',round(f6,2)))\n",
        "print( \"{:<35}\".format(\"**Mod-2 DOBSS,K=-0.5,L=0.5\")    ,\"{:<10} {:1} {:<10}\".format(  round(v7,2),'|',round(f7,2)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tcUCP4FOnA3"
      },
      "source": [
        "# 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GOAZ0FeOovu"
      },
      "source": [
        "To understand how the choices made can be different, let us look at the example below where we restrict the leader strategy choice to only pure strategies, and compare it with the results of individual pure strategies. No mixed strategies can be chosen so the action space remains finite and it is easier for our understanding.\n",
        "\n",
        "From here, we can get a vague understanding regarding how strategies are evaluated based on the parameters (L,K) and how a strategy is being chosen for the follower by the algorithm.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psBfp76IOpZt",
        "outputId": "46d7c7be-93b9-4157-fa85-8619d6e6c39c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[10. ,  9. ,  8. ,  5. ,  4. ,  2. ],\n",
            "       [10. ,  9.5,  8.5,  5. ,  4. ,  0. ]])]\n",
            "[array([[10. , 10. ,  9. ,  5. ,  4.5,  4. ],\n",
            "       [10. , 10. ,  9. ,  5. ,  4. ,  3. ]])]\n",
            "---------------------------------------------\n",
            "\n",
            "Original DOBSS\n",
            "                Leader     | Follower  \n",
            "Original DOBSS  10.0       | 10.0      \n",
            "---------------------------------------------\n",
            "\n",
            "Mod-1 DOBSS\n",
            "                Leader     | Follower  \n",
            "Mod-1 DOBSS     9.5        | 10.0      \n",
            "---------------------------------------------\n",
            "\n",
            "Mod-2 DOBSS\n",
            "                Leader     | Follower  \n",
            "K=1,L=1         9.5        | 10.0      \n",
            "K=1,L=2.5       8.5        | 9.0       \n",
            "K=1,L=5.5       5.0        | 5.0       \n",
            "K=1,L=6.5       4.0        | 4.0       \n",
            "K=1,L=7.5       2.0        | 4.0       \n"
          ]
        }
      ],
      "source": [
        "R = [np.asarray ( [[ 10,9,8,5,4,2],\n",
        "                   [ 10, 9.5, 8.5, 5,4,0]\n",
        "                   ] ) ]\n",
        "print(R)\n",
        "\n",
        "C = [np.asarray ( [[ 10,10,9,5,4.5,4],\n",
        "                   [ 10,10,9,5,4,3]\n",
        "                   ] ) ]\n",
        "print(C)\n",
        "\n",
        "p = [1]\n",
        "\n",
        "\n",
        "print(\"---------------------------------------------\\n\")\n",
        "print(\"Original DOBSS\")\n",
        "print(  \"{:<15}\".format(\" \"), \"{:<10} {:1} {:<10}\".format(  \"Leader\",'|', \"Follower\"  ))\n",
        "v1,f1,Z1 = optimal_strategy(R,C,p,show=False,solver=0,lp=1)\n",
        "print( \"{:<15}\".format(\"Original DOBSS\") ,\"{:<10} {:1} {:<10}\".format(  round(v1,2),'|',round(f1,2)))\n",
        "\n",
        "print(\"---------------------------------------------\\n\")\n",
        "v2,f2,Z2 = optimal_strategy(R,C,p,show=False,solver=1,Δ=0,lp=1)\n",
        "print(\"Mod-1 DOBSS\")\n",
        "print(  \"{:<15}\".format(\" \"), \"{:<10} {:1} {:<10}\".format(  \"Leader\",'|', \"Follower\"  ))\n",
        "print( \"{:<15}\".format(\"Mod-1 DOBSS\")    ,\"{:<10} {:1} {:<10}\".format(  round(v2,2),'|',round(f2,2)))\n",
        "\n",
        "\n",
        "print(\"---------------------------------------------\\n\")\n",
        "\n",
        "print(\"Mod-2 DOBSS\")\n",
        "print(  \"{:<15}\".format(\" \"), \"{:<10} {:1} {:<10}\".format(  \"Leader\",'|', \"Follower\"  ))\n",
        "v3,f3,Z = optimal_strategy2(R,C,p,show=False,K=1,L=1,solver=0,lp=1)\n",
        "print( \"{:<15}\".format(\"K=1,L=1\")    ,\"{:<10} {:1} {:<10}\".format(  round(v3,2),'|',round(f3,2)))\n",
        "v3,f3,Z = optimal_strategy2(R,C,p,show=False,K=0.5,L=2.5,solver=0,lp=1)\n",
        "print( \"{:<15}\".format(\"K=1,L=2.5\")    ,\"{:<10} {:1} {:<10}\".format(  round(v3,2),'|',round(f3,2)))\n",
        "v3,f3,Z = optimal_strategy2(R,C,p,show=False,K=0.5,L=5.5,solver=0,lp=1)\n",
        "print( \"{:<15}\".format(\"K=1,L=5.5\")    ,\"{:<10} {:1} {:<10}\".format(  round(v3,2),'|',round(f3,2)))\n",
        "v3,f3,Z = optimal_strategy2(R,C,p,show=False,K=0.5,L=6.5,solver=0,lp=1)\n",
        "print( \"{:<15}\".format(\"K=1,L=6.5\")    ,\"{:<10} {:1} {:<10}\".format(  round(v3,2),'|',round(f3,2)))\n",
        "v3,f3,Z = optimal_strategy2(R,C,p,show=False,K=0.5,L=7.5,solver=0,lp=1)\n",
        "print( \"{:<15}\".format(\"K=1,L=7.5\")    ,\"{:<10} {:1} {:<10}\".format(  round(v3,2),'|',round(f3,2)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlteGJ6dkMqd",
        "outputId": "ba403943-3256-4be1-9f88-f7c5fdb999eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pure strategy 1 only\n",
            "[array([[10,  9,  8,  5,  4,  2]])]\n",
            "[array([[10. , 10. ,  9. ,  5. ,  4.5,  4. ]])]\n",
            "---------------------------------------------\n",
            "\n",
            "Original DOBSS\n",
            "                Leader     | Follower  \n",
            "Original DOBSS  10.0       | 10.0      \n",
            "---------------------------------------------\n",
            "\n",
            "Mod-1 DOBSS\n",
            "                Leader     | Follower  \n",
            "Mod-1 DOBSS     9.0        | 10.0      \n",
            "---------------------------------------------\n",
            "\n",
            "Mod-2 DOBSS\n",
            "                Leader     | Follower  \n",
            "K=1,L=1         9.0        | 10.0      \n",
            "K=1,L=2.5       8.0        | 9.0       \n",
            "K=1,L=5.5       5.0        | 5.0       \n",
            "K=1,L=6.5       2.0        | 4.0       \n",
            "K=1,L=7.5       2.0        | 4.0       \n"
          ]
        }
      ],
      "source": [
        "print(\"Pure strategy 1 only\")\n",
        "\n",
        "R = [np.asarray ( [[ 10,9,8,5,4,2]\n",
        "                   ] ) ]\n",
        "print(R)\n",
        "\n",
        "C = [np.asarray ( [[ 10,10,9,5,4.5,4]\n",
        "                   ] ) ]\n",
        "print(C)\n",
        "\n",
        "p = [1]\n",
        "\n",
        "\n",
        "print(\"---------------------------------------------\\n\")\n",
        "print(\"Original DOBSS\")\n",
        "print(  \"{:<15}\".format(\" \"), \"{:<10} {:1} {:<10}\".format(  \"Leader\",'|', \"Follower\"  ))\n",
        "v1,f1,Z = optimal_strategy(R,C,p,show=False,solver=0,lp=1)\n",
        "print( \"{:<15}\".format(\"Original DOBSS\") ,\"{:<10} {:1} {:<10}\".format(  round(v1,2),'|',round(f1,2)))\n",
        "\n",
        "print(\"---------------------------------------------\\n\")\n",
        "v2,f2,Z = optimal_strategy(R,C,p,show=False,solver=1,Δ=0,lp=1)\n",
        "print(\"Mod-1 DOBSS\")\n",
        "print(  \"{:<15}\".format(\" \"), \"{:<10} {:1} {:<10}\".format(  \"Leader\",'|', \"Follower\"  ))\n",
        "print( \"{:<15}\".format(\"Mod-1 DOBSS\")    ,\"{:<10} {:1} {:<10}\".format(  round(v2,2),'|',round(f2,2)))\n",
        "\n",
        "\n",
        "print(\"---------------------------------------------\\n\")\n",
        "\n",
        "print(\"Mod-2 DOBSS\")\n",
        "print(  \"{:<15}\".format(\" \"), \"{:<10} {:1} {:<10}\".format(  \"Leader\",'|', \"Follower\"  ))\n",
        "v3,f3,Z = optimal_strategy2(R,C,p,show=False,K=1,L=1,solver=0,lp=1)\n",
        "print( \"{:<15}\".format(\"K=1,L=1\")    ,\"{:<10} {:1} {:<10}\".format(  round(v3,2),'|',round(f3,2)))\n",
        "v3,f3,Z = optimal_strategy2(R,C,p,show=False,K=0.5,L=2.5,solver=0,lp=1)\n",
        "print( \"{:<15}\".format(\"K=1,L=2.5\")    ,\"{:<10} {:1} {:<10}\".format(  round(v3,2),'|',round(f3,2)))\n",
        "v3,f3,Z = optimal_strategy2(R,C,p,show=False,K=0.5,L=5.5,solver=0,lp=1)\n",
        "print( \"{:<15}\".format(\"K=1,L=5.5\")    ,\"{:<10} {:1} {:<10}\".format(  round(v3,2),'|',round(f3,2)))\n",
        "v3,f3,Z = optimal_strategy2(R,C,p,show=False,K=0.5,L=6.5,solver=0,lp=1)\n",
        "print( \"{:<15}\".format(\"K=1,L=6.5\")    ,\"{:<10} {:1} {:<10}\".format(  round(v3,2),'|',round(f3,2)))\n",
        "v3,f3,Z = optimal_strategy2(R,C,p,show=False,K=0.5,L=7.5,solver=0,lp=1)\n",
        "print( \"{:<15}\".format(\"K=1,L=7.5\")    ,\"{:<10} {:1} {:<10}\".format(  round(v3,2),'|',round(f3,2)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sETRLcsfkMeY",
        "outputId": "890dc5dd-ef5c-429d-df46-a35aac9d97e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pure strategy 2 only\n",
            "[array([[10. ,  9.5,  8.5,  5. ,  4. ,  0. ]])]\n",
            "[array([[10, 10,  9,  5,  4,  3]])]\n",
            "---------------------------------------------\n",
            "\n",
            "Original DOBSS\n",
            "                Leader     | Follower  \n",
            "Original DOBSS  10.0       | 10.0      \n",
            "---------------------------------------------\n",
            "\n",
            "Mod-1 DOBSS\n",
            "                Leader     | Follower  \n",
            "Mod-1 DOBSS     9.5        | 10.0      \n",
            "---------------------------------------------\n",
            "\n",
            "Mod-2 DOBSS\n",
            "                Leader     | Follower  \n",
            "K=1,L=1         9.5        | 10.0      \n",
            "K=1,L=2.5       8.5        | 9.0       \n",
            "K=1,L=5.5       5.0        | 5.0       \n",
            "K=1,L=6.5       4.0        | 4.0       \n",
            "K=1,L=7.5       0.0        | 3.0       \n"
          ]
        }
      ],
      "source": [
        "print(\"Pure strategy 2 only\")\n",
        "\n",
        "R = [np.asarray ( [\n",
        "                   [ 10, 9.5, 8.5, 5,4,0]\n",
        "                   ] ) ]\n",
        "print(R)\n",
        "\n",
        "C = [np.asarray ( [\n",
        "                   [ 10,10,9,5,4,3]\n",
        "                   ] ) ]\n",
        "print(C)\n",
        "\n",
        "p = [1]\n",
        "\n",
        "\n",
        "print(\"---------------------------------------------\\n\")\n",
        "print(\"Original DOBSS\")\n",
        "print(  \"{:<15}\".format(\" \"), \"{:<10} {:1} {:<10}\".format(  \"Leader\",'|', \"Follower\"  ))\n",
        "v1,f1,Z = optimal_strategy(R,C,p,show=False,solver=0,lp=1)\n",
        "print( \"{:<15}\".format(\"Original DOBSS\") ,\"{:<10} {:1} {:<10}\".format(  round(v1,2),'|',round(f1,2)))\n",
        "\n",
        "print(\"---------------------------------------------\\n\")\n",
        "v2,f2,Z = optimal_strategy(R,C,p,show=False,solver=1,Δ=0,lp=1)\n",
        "print(\"Mod-1 DOBSS\")\n",
        "print(  \"{:<15}\".format(\" \"), \"{:<10} {:1} {:<10}\".format(  \"Leader\",'|', \"Follower\"  ))\n",
        "print( \"{:<15}\".format(\"Mod-1 DOBSS\")    ,\"{:<10} {:1} {:<10}\".format(  round(v2,2),'|',round(f2,2)))\n",
        "\n",
        "\n",
        "print(\"---------------------------------------------\\n\")\n",
        "\n",
        "print(\"Mod-2 DOBSS\")\n",
        "print(  \"{:<15}\".format(\" \"), \"{:<10} {:1} {:<10}\".format(  \"Leader\",'|', \"Follower\"  ))\n",
        "v3,f3,Z = optimal_strategy2(R,C,p,show=False,K=1,L=1,solver=0,lp=1)\n",
        "print( \"{:<15}\".format(\"K=1,L=1\")    ,\"{:<10} {:1} {:<10}\".format(  round(v3,2),'|',round(f3,2)))\n",
        "v3,f3,Z = optimal_strategy2(R,C,p,show=False,K=0.5,L=2.5,solver=0,lp=1)\n",
        "print( \"{:<15}\".format(\"K=1,L=2.5\")    ,\"{:<10} {:1} {:<10}\".format(  round(v3,2),'|',round(f3,2)))\n",
        "v3,f3,Z = optimal_strategy2(R,C,p,show=False,K=0.5,L=5.5,solver=0,lp=1)\n",
        "print( \"{:<15}\".format(\"K=1,L=5.5\")    ,\"{:<10} {:1} {:<10}\".format(  round(v3,2),'|',round(f3,2)))\n",
        "v3,f3,Z = optimal_strategy2(R,C,p,show=False,K=0.5,L=6.5,solver=0,lp=1)\n",
        "print( \"{:<15}\".format(\"K=1,L=6.5\")    ,\"{:<10} {:1} {:<10}\".format(  round(v3,2),'|',round(f3,2)))\n",
        "v3,f3,Z = optimal_strategy2(R,C,p,show=False,K=0.5,L=7.5,solver=0,lp=1)\n",
        "print( \"{:<15}\".format(\"K=1,L=7.5\")    ,\"{:<10} {:1} {:<10}\".format(  round(v3,2),'|',round(f3,2)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pBmsWemIdVqN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "VKbOB7nB7tyk",
        "j4lhIBpNC7Br",
        "DMEapV9l8hYP"
      ],
      "name": "DOBSS testing 1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}