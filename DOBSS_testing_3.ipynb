{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKbOB7nB7tyk"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fi_KiXt7s2q"
      },
      "outputs": [],
      "source": [
        "import cvxpy as cp\n",
        "import numpy as np\n",
        "import random\n",
        "from scipy.optimize import linprog\n",
        "from tqdm import tqdm\n",
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def printf(s):\n",
        "  s = '\\n\\033[43m'+ '\\033[1m' + str(s) + '\\033[0m \\n'\n",
        "  print(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4lhIBpNC7Br"
      },
      "source": [
        "# Random Test case generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0gPDJ4IDAww"
      },
      "outputs": [],
      "source": [
        "def create(m,n):\n",
        "\n",
        "  if type(n) is int:\n",
        "    n = [n]\n",
        "\n",
        "  R = []; C = []\n",
        "  for i in range(len(n)):\n",
        "    R.append(np.random.randint(100,size=(m,n[i])))\n",
        "    C.append(np.random.randint(100,size=(m,n[i])))\n",
        "  \n",
        "  p = [1/len(n)]*len(n)\n",
        "  return R,C,p\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZM_u8ZU70-y"
      },
      "source": [
        "# DOBSS and DOBSS modification 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOqaihss78Fm"
      },
      "outputs": [],
      "source": [
        "# Stackelberg game solution -> without change\n",
        "def formulate_sg(R,C,p,M=1e3,Δ=0,lp=0):\n",
        "\n",
        "  m,n = R.shape\n",
        "\n",
        "  z = cp.Variable((m,n), nonneg=True)\n",
        "  q = cp.Variable(n,integer=True)\n",
        "  a = cp.Variable(1)\n",
        "\n",
        "  obj = p*cp.Maximize(sum(sum(cp.multiply(R,z))))\n",
        "  con = [#z<=1,q<=1, #feasibility, but this is implied by the following constraints\n",
        "         \n",
        "         0<=q,\n",
        "         sum(sum(z))==1, #sum of all xi's=1 -> belongs to probability simplex\n",
        "         sum(z.T)<=1, #individual xi's <=1 -> belongs to probability simplex\n",
        "\n",
        "         q<=sum(z), sum(z)<=1, #as zij=xi.qj\n",
        "         sum(q)==1, #sum of all qj's=1 -> belongs to probability simplex\n",
        "\n",
        "         0<=a-sum(z.T)@C, a-sum(z.T)@C-M*(1-q)<=0, #follower's problem -> maximizing follower revenue\n",
        "\n",
        "       ]\n",
        "\n",
        "  if lp==1:\n",
        "    x = cp.Variable(m,integer=True)\n",
        "    con+=[sum(z.T)==x]\n",
        "\n",
        "  return obj, con, z, q\n",
        "\n",
        "\n",
        "# Stackelberg game solution \n",
        "def formulate_sg2(R,C,p,M=1e3,Δ=0,lp=0):\n",
        "\n",
        "  m,n = R.shape\n",
        "\n",
        "  z = cp.Variable((m,n), nonneg=True)\n",
        "  q = cp.Variable(n,integer=True)\n",
        "  a = cp.Variable(1)\n",
        "\n",
        "  obj = p*cp.Maximize(sum(sum(cp.multiply(R,z))))\n",
        "  con = [\n",
        "         \n",
        "        #  z<=1,q<=1, #feasibility, but this is implied by the following constraints\n",
        "         0<=q,\n",
        "         sum(sum(z))==1, #sum of all xi's=1 -> belongs to probability simplex\n",
        "         sum(z.T)<=1, #individual xi's <=1 -> belongs to probability simplex\n",
        "\n",
        "         q<=sum(z), sum(z)<=1, #as zij=xi.qj\n",
        "         sum(q)==1, #sum of all qj's=1 -> belongs to probability simplex\n",
        "\n",
        "        #  x == sum(z.T), # by definition\n",
        "        #  0<=a-x@C, a-x@C-1e3*(1-q)<=0, #follower's problem -> maximizing follower revenue\n",
        "         0<=a-sum(z.T)@C, a-sum(z.T)@C-M*(1-q)<=0, #follower's problem -> maximizing follower revenue\n",
        "         sum(sum(cp.multiply(R,z))) <= Δ + sum(z.T)@R + M*( sum(sum(cp.multiply(C,z))) - sum(z.T)@C ) # Select the payoff of leader which minimum among all available maximizing strategies of follower\n",
        "       ]\n",
        "\n",
        "  if lp==1:\n",
        "    x = cp.Variable(m,integer=True)\n",
        "    con+=[sum(z.T)==x]\n",
        "\n",
        "  return obj, con, z, q\n",
        "\n",
        "\n",
        "# Bayesian Stackelberg game solution \n",
        "def formulate_bsg(R,C,p,solver=1,Δ=0,lp=0):\n",
        "\n",
        "  for l in range(len(R)):\n",
        "    if solver==0:\n",
        "      o,c,z,q = formulate_sg(R[l],C[l],p[l],Δ=Δ,lp=lp)\n",
        "    elif solver==1:\n",
        "      o,c,z,q = formulate_sg2(R[l],C[l],p[l],Δ=Δ,lp=lp)\n",
        "\n",
        "    if l == 0:\n",
        "      Obj = o\n",
        "      Con = c\n",
        "      Z = [z]\n",
        "      Q = [q]\n",
        "    else:\n",
        "      Obj += o\n",
        "      Con += c\n",
        "      Z +=[z]\n",
        "      Q +=[q]\n",
        "\n",
        "  return Obj,Con,Z,Q \n",
        "\n",
        "\n",
        "# Solver of the game \n",
        "def optimal_strategy(R,C,p,show=False,solver=0,Δ=0,lp=0):\n",
        "\n",
        "  obj, con, Z, Q = formulate_bsg(R,C,p,solver=solver,Δ=Δ,lp=lp)\n",
        "\n",
        "  if len(Z)>1:\n",
        "    c2 = []\n",
        "    for l in range(len(Z)):\n",
        "      if l==0:\n",
        "        k = sum(Z[l].T)\n",
        "      else:\n",
        "        c2+=[k==sum(Z[l].T)] # additional constraint for all xi's to be equal    \n",
        "    con+=c2\n",
        "\n",
        "  prob = cp.Problem(obj, con)\n",
        "  # The optimal objective value is returned by `prob.solve()`.\n",
        "  result = prob.solve()\n",
        "\n",
        "  for i in range(len(Z)):\n",
        "    if i == 0:\n",
        "      zf = np.sum(np.asarray(Z[i].value),axis=1)/len(Z)\n",
        "    else:\n",
        "      zf += np.sum(np.asarray(Z[i].value),axis=1)/len(Z)\n",
        "\n",
        "\n",
        "  ans = 0\n",
        "  ans2 = 0\n",
        "  for i in range(len(Z)):\n",
        "    ans += np.sum(Z[i].value*R[i])*p[i]\n",
        "    ans2 += np.sum(Z[i].value*C[i])*p[i]\n",
        "\n",
        "\n",
        "  if show==True:\n",
        "\n",
        "    print(\"-------------------------------------------------\")\n",
        "    printf('Solver='+str(solver)+'  Δ='+str(Δ))\n",
        "    print(\"Optimal value: \",prob.value,'\\n\\n')\n",
        "    print(\"Leader\\'s strategy\",'\\n',zf,'\\n\\n')\n",
        "    print(\"Follower strategies - for different types\")\n",
        "    for i in range(len(Z)):\n",
        "      print(\"Player type\",i,\" : \", Q[i].value)\n",
        "    print('\\n')\n",
        "    print(\"-------------------------------------------------\")\n",
        "\n",
        "  return ans, ans2, Z # strategy profile\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCTM7MIf8NZJ"
      },
      "source": [
        "# DOBSS modification 2,3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOQNhMJI8PY8"
      },
      "outputs": [],
      "source": [
        "def formulate_sg_ir2(R,C,p,K=1/2,L=10,frac=0.10,solver=0,lp=0):\n",
        "\n",
        "  m,n = R.shape\n",
        "  # M = max(np.max(abs(R)),np.max(abs(C)))+1e3\n",
        "  M=1e2\n",
        "\n",
        "  K2=1\n",
        "  if K<=1:\n",
        "    K2=K\n",
        "    K=1\n",
        "\n",
        "  z = cp.Variable((m,n), nonneg=True)\n",
        "  w = cp.Variable((m,n), nonneg=True)\n",
        "  q = cp.Variable(n,integer=True)\n",
        "  r = cp.Variable(n,integer=True)\n",
        "  g = cp.Variable(n,integer=True) \n",
        "  a = cp.Variable(1)\n",
        "\n",
        "  con = []\n",
        "\n",
        "  if solver!=0:\n",
        "    L = cp.Variable(1)\n",
        "    con+=[L==a*frac]\n",
        "\n",
        "  obj = p*cp.Maximize(sum(sum(cp.multiply(R,w))))\n",
        "  con +=[\n",
        "         # Constraints from DOBSS\n",
        "         sum(sum(z))==1,                                                                                     # Sum of all xi's=1     -> belongs to probability simplex\n",
        "         sum(z.T)<=1,                                                                                        # Individual xi's <=1   -> belongs to probability simplex\n",
        "         0<=q, sum(q)==1,                                                                                    # Sum of all qj's=1     -> belongs to probability simplex\n",
        "         q<=sum(z), sum(z)<=1,                                                                               # As zij=xi.qj          -> definition of zij's\n",
        "         0<=a-sum(z.T)@C, a-sum(z.T)@C-M*(1-q)<=0,                                                           #           a           -> Max follower payoff for given leader strategy\n",
        "\n",
        "         # Constraints for modelling Irrational behaviour         \n",
        "         g<=1, 0<=g,                                                                                         # Truth value variables -> binary\n",
        "         sum(z.T) == sum(w.T),                                                                               # As wij=xi.q'j         -> definition of wij's\n",
        "         r<=sum(w),\n",
        "         0<=r, sum(r)==1,\n",
        "         K2*(sum(sum(cp.multiply(C,w))) - sum(w.T)@C) >= (sum(sum(cp.multiply(R,w))) - sum(w.T)@R)/K - M*g,  # Comparisions          -> the loss of follower < k*(loss of leader) \n",
        "         a - sum(sum(cp.multiply(C,w))) <= L,                                                                # Stop loss condition   -> the loss of follower <= stop loss\n",
        "         a - sum(w.T)@C >= L - M*(1-g),                                                                      # Stop loss criterion   -> truth value from g \n",
        "         a - sum(w.T)@C <= L + M*g                                                                           # Stop loss criterion   -> truth value from g \n",
        "       ]\n",
        "\n",
        "\n",
        "  if lp==1:\n",
        "    x = cp.Variable(m,integer=True)\n",
        "    con+=[sum(z.T)==x]\n",
        "    con+=[sum(w.T)==x]\n",
        "\n",
        "  return obj, con, w, z, q, g, a, r\n",
        "\n",
        "\n",
        "\n",
        "# Bayesian Stackelberg game solution \n",
        "def formulate_bsg2(R,C,p,solver=0,K=2,L=10,frac=0.1,lp=0):\n",
        "\n",
        "  for l in range(len(R)):\n",
        "\n",
        "    o, c, w, z, q, g, a, r = formulate_sg_ir2(R[l],C[l],p[l],K=K,L=L,solver=solver,frac=frac,lp=lp)    \n",
        "\n",
        "    if l == 0:\n",
        "      Obj = o\n",
        "      Con = c\n",
        "      W = [w]\n",
        "      Z = [z]\n",
        "      Q = [q]\n",
        "      G = [g]\n",
        "      A = [a]\n",
        "      Rr = [r]\n",
        "\n",
        "    else:\n",
        "      Obj += o\n",
        "      Con += c\n",
        "      W += [w]\n",
        "      Z += [z]\n",
        "      Q += [q]\n",
        "      G += [g]\n",
        "      A += [a]\n",
        "      Rr += [r]\n",
        "\n",
        "  return Obj,Con,W,Z,Q,G,A,Rr\n",
        "\n",
        "\n",
        "def optimal_strategy2(R,C,p,show=False,K=2,L=10,solver=0,frac=0,lp=0):\n",
        "\n",
        "  Obj,Con,W,Z,Q,G,A,Rr = formulate_bsg2(R,C,p,K=K,L=L,solver=solver,frac=frac,lp=lp)\n",
        "\n",
        "  if len(W)>1:\n",
        "    c2 = []\n",
        "    for l in range(len(W)):\n",
        "      if l==0:\n",
        "        k = sum(W[l].T)\n",
        "      else:\n",
        "        c2+=[k==sum(W[l].T)] # additional constraint for all xi's to be equal    \n",
        "    Con+=c2\n",
        "\n",
        "  prob = cp.Problem(Obj,Con)\n",
        "  result = prob.solve()\n",
        "\n",
        "  ans = 0\n",
        "  ans2 = 0\n",
        "  for i in range(len(W)):\n",
        "    ans += np.sum(W[i].value*R[i])*p[i]\n",
        "    ans2 += np.sum(W[i].value*C[i])*p[i]\n",
        "\n",
        "  for i in range(len(W)):\n",
        "    if i == 0:\n",
        "      wf = np.sum(np.asarray(W[i].value),axis=1)\n",
        "    else:\n",
        "      wf += np.sum(np.asarray(W[i].value),axis=1)\n",
        "  wf = wf/len(W)\n",
        "\n",
        "\n",
        "  if show == True:\n",
        "\n",
        "    if solver == 0:\n",
        "      printf('Solver='+str(solver+3)+'  K-factor='+str(K) +';  Stop loss ='+str(L))\n",
        "    else:\n",
        "      printf('Solver='+str(solver+3)+'  K-factor='+str(K) +';  Fractional loss ='+str(frac))\n",
        "\n",
        "    print(\"-------------------------------------------------\")\n",
        "    print(\"Objective value \"+str(ans))\n",
        "\n",
        "    print(\"-------------------------------------------------\")\n",
        "    print(\"W\")\n",
        "    for i in range(len(W)):\n",
        "      print(\"player type \",i+1)\n",
        "      print(W[i].value)\n",
        "\n",
        "    print(\"-------------------------------------------------\")\n",
        "    print(\"Z\")\n",
        "    for i in range(len(Z)):\n",
        "      print(\"player type \",i+1)\n",
        "      print(Z[i].value)\n",
        "    \n",
        "    print(\"-------------------------------------------------\")\n",
        "    print(\"Q\")\n",
        "    for i in range(len(Q)):\n",
        "      print(\"player type \",i+1)\n",
        "      print(Q[i].value)\n",
        "\n",
        "    print(\"-------------------------------------------------\")\n",
        "    print(\"G\")\n",
        "    for i in range(len(G)):\n",
        "      print(\"player type \",i+1)\n",
        "      print(G[i].value)\n",
        "    \n",
        "    print(\"-------------------------------------------------\")\n",
        "    print(\"A\")\n",
        "    for i in range(len(A)):\n",
        "      print(\"player type \",i+1)\n",
        "      print(A[i].value)\n",
        "\n",
        "    print(\"-------------------------------------------------\")\n",
        "    print(\"Rr\")\n",
        "    for i in range(len(Rr)):\n",
        "      print(\"player type \",i+1)\n",
        "      print(Rr[i].value)\n",
        "\n",
        "    print(\"-------------------------------------------------\")\n",
        "\n",
        "    print(\"Leader payoff: \",ans,'\\n\\n')\n",
        "    \n",
        "    print(\"Follower payoff - for different types\")\n",
        "    for i in range(len(W)):\n",
        "      print(\"Player type\",i,\" : \", np.sum(W[i].value*C[i]))\n",
        "    print('\\n')\n",
        "\n",
        "    print(\"-------------------------------------------------\")\n",
        "\n",
        "    print(\"Leader\\'s strategy\",'\\n',wf,'\\n\\n')\n",
        "\n",
        "    print(\"Follower strategies - for different types\")\n",
        "    L2 = []\n",
        "    for i in range(len(W)):\n",
        "      print(\"Player type\",i,\" : \", np.sum(np.asarray(W[i].value),axis=0))\n",
        "      L2.append(np.sum(np.asarray(W[i].value),axis=0))\n",
        "    print('\\n')\n",
        "    \n",
        "    for i in range(len(W)):\n",
        "      print(\"W matrix\",i,\" : \", np.asarray(W[i].value))\n",
        "    print('\\n')\n",
        "\n",
        "    print(\"-------------------------------------------------\")\n",
        "\n",
        "\n",
        "  return ans, ans2, W \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMEapV9l8hYP"
      },
      "source": [
        "# Comparing solutions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-MFwUrGeeyd"
      },
      "source": [
        "# 4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OllfMdl4yMR"
      },
      "source": [
        "## Testing the effect of the parameter `L` in choosing a mixed strategy.\n",
        "\n",
        "Here is a simple example where we see a mixed strategy is chosen by the algorithm as an output which shows some characteristics of risk avoidance.\n",
        "\n",
        "Here, we see how we pick a mixed strategy based on the amount of loss that is being dictated by the stop loss parameter `L`. (Here, we would like to limit the effect of choice with respect to the parameter `K`, so `K` is chosen to be small and the selected parameter is unaffected by `K`)\n",
        "\n",
        "The example is as follows:\n",
        "\n",
        "|      | G1 | G2 |\n",
        "|:---  |:---:|:---:|\n",
        "|**B1**| 4,5 | 6,5 |\n",
        "|**B2**| 5,4 | 5,5 |\n",
        "\n",
        "\n",
        "There is a risky strategy `B1` for the leader and another strategy `B2`, which is not very risky.\n",
        "The follower has `G1` and `G2`, where `G2` is his stable strategy and `G2` is when he wants to take loss to incur damage to the leader. Now the leader has to mix his strategies in order to make the follower believe the loss faced by it will exceed it's stop loss if it choses the damage incurring strategy.\n",
        "\n",
        "The results also reflect the same, with an increase in value of `L`, the strategy chosen is more conservative and the probability for picking the riskier strategy is becoming lesser and lesser. The payoff is also becoming lower as the risk is lowered."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "R = [np.asarray ( [[ 4, 6 ],\n",
        "                   [ 5, 5 ]\n",
        "                   ] ) ]\n",
        "# print(R)\n",
        "\n",
        "C = [np.asarray ( [[ 5, 5 ],\n",
        "                   [ 4, 5 ]\n",
        "                   ] ) ]\n",
        "# print(C)\n",
        "\n",
        "p = [1]\n",
        "\n",
        "\n",
        "print(\"---------------------------------------------\\n\")\n",
        "print(\"Original DOBSS\")\n",
        "print(  \"{:<15}\".format(\" \"), \"{:<10} {:1} {:<10}\".format(  \"Leader\",'|', \"Follower\"  ))\n",
        "v1,f1,Z1 = optimal_strategy(R,C,p,show=False,solver=0,lp=0)\n",
        "print( \"{:<15}\".format(\"Original DOBSS\") ,\"{:<10} {:1} {:<10}\".format(  round(v1,2),'|',round(f1,2)))\n",
        "\n",
        "print(\"---------------------------------------------\\n\")\n",
        "v2,f2,Z2 = optimal_strategy(R,C,p,show=False,solver=1,Δ=0,lp=0)\n",
        "print(\"Mod-1 DOBSS\")\n",
        "print(  \"{:<15}\".format(\" \"), \"{:<10} {:1} {:<10}\".format(  \"Leader\",'|', \"Follower\"  ))\n",
        "print( \"{:<15}\".format(\"Mod-1 DOBSS\")    ,\"{:<10} {:1} {:<10}\".format(  round(v2,2),'|',round(f2,2)))\n",
        "\n",
        "\n",
        "print(\"---------------------------------------------\\n\")\n",
        "\n",
        "print(\"Mod-2 DOBSS\")\n",
        "print(  \"{:<15}\".format(\" \"), \"{:<10} {:1} {:<10}\".format(  \"Leader\",'|', \"Follower\"  ))\n",
        "v3,f3,Z = optimal_strategy2(R,C,p,show=False,K=0.1,L=0.9,solver=0,lp=0)\n",
        "print( \"{:<15}\".format(\"K=0.1,L=1.1\")    ,\"{:<10} {:1} {:<10}\".format(  round(v3,2),'|',round(f3,2)))\n",
        "\n",
        "v3,f3,Z = optimal_strategy2(R,C,p,show=False,K=0.1,L=0.5,solver=0,lp=0)\n",
        "print( \"{:<15}\".format(\"K=0.1,L=0.5\")    ,\"{:<10} {:1} {:<10}\".format(  round(v3,2),'|',round(f3,2)))\n",
        "\n",
        "v3,f3,Z = optimal_strategy2(R,C,p,show=False,K=0.1,L=0.1,solver=0,lp=0)\n",
        "print( \"{:<15}\".format(\"K=0.1,L=0.3\")    ,\"{:<10} {:1} {:<10}\".format(  round(v3,2),'|',round(f3,2)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuzxeLZter4m",
        "outputId": "28863426-6f00-44ed-8100-711032379ac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------\n",
            "\n",
            "Original DOBSS\n",
            "                Leader     | Follower  \n",
            "Original DOBSS  6.0        | 5.0       \n",
            "---------------------------------------------\n",
            "\n",
            "Mod-1 DOBSS\n",
            "                Leader     | Follower  \n",
            "Mod-1 DOBSS     6.0        | 5.0       \n",
            "---------------------------------------------\n",
            "\n",
            "Mod-2 DOBSS\n",
            "                Leader     | Follower  \n",
            "K=0.1,L=1.1     5.1        | 5.0       \n",
            "K=0.1,L=0.5     5.5        | 5.0       \n",
            "K=0.1,L=0.3     5.9        | 5.0       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the effect of the parameter `K` in choosing a mixed strategy.\n",
        "\n",
        "Here, we see how we pick a mixed strategy based on the  that is being dictated by the stop loss parameter `L`. (Here, we would like to limit the effect of choice with respect to the parameter `K`, so `K` is chosen to be small and the selected parameter is unaffected by `K`)\n",
        "\n",
        "The example is as follows:\n",
        "\n",
        "|      | G1 | G2 |\n",
        "|:---  |:---:|:---:|\n",
        "|**B1**| 1,1 | 0,0 |\n",
        "|**B2**| 0,1 | 0,0 |\n",
        "\n",
        "\n",
        "B1,G1 is the only pair strategy here which gives the leader a non zero payoff.\n",
        "G1 gives the follower a guaranteed payoff of 1 and G2 gives 0. So, if the follower is willing to take a loss, then he will choose G2. But he will only take a loss if the leader is losing some sufficient amount of payoff.\n",
        "\n",
        "The leader has to make it look less appealing for the follower to choose G2 by mixing B1, B2 with some probabilities such that the follower will not want to take the loss for the sake of making the leader lose some insufficient amount of payoff.\n",
        "\n",
        "In the following test runs, we see that:-\n",
        "* When the follower has a K value of `x`, follower is not going to sacrifice it's utility for the sake of reducing the payoff of follower by any amount less than K times it's loss. \n",
        "* So, the leader can choose the mixing probabilities so as to make the follower not choose the irrational strategy to lower his payoff.\n",
        "\n",
        "The results also reflect the same, an increase in value of `K` indicates that the follower is not very easily giving up his payoff. So, the estimates payoffs are higher in the hope that follower doesn't deviate much from perfect rationality.\n",
        "\n",
        "With decrease in `k` value, we are giving a more conservative estimate, hence follower tends to choose the `taking a hit on self payoff` strategy to make the other option look little less appealing. So, in a way the algorithm would output a follower strategy which is not very appealing to deviate from for the follower and hence it adds stability for the picked strategies.\n"
      ],
      "metadata": {
        "id": "6agIGJXYq2VF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "R = [np.asarray ( [[ 1, 0 ],\n",
        "                   [ 0, 0 ]\n",
        "                   ] ) ]\n",
        "# print(R)\n",
        "\n",
        "C = [np.asarray ( [[ 1, 0 ],\n",
        "                   [ 1, 0 ]\n",
        "                   ] ) ]\n",
        "# print(C)\n",
        "\n",
        "p = [1]\n",
        "\n",
        "\n",
        "print(\"---------------------------------------------\\n\")\n",
        "print(\"Original DOBSS\")\n",
        "print(  \"{:<15}\".format(\" \"), \"{:<10} {:1} {:<10}\".format(  \"Leader\",'|', \"Follower\"  ))\n",
        "v1,f1,Z1 = optimal_strategy(R,C,p,show=False,solver=0,lp=0)\n",
        "print( \"{:<15}\".format(\"Original DOBSS\") ,\"{:<10} {:1} {:<10}\".format(  round(v1,2),'|',round(f1,2)))\n",
        "\n",
        "print(\"---------------------------------------------\\n\")\n",
        "v2,f2,Z2 = optimal_strategy(R,C,p,show=False,solver=1,Δ=0,lp=0)\n",
        "print(\"Mod-1 DOBSS\")\n",
        "print(  \"{:<15}\".format(\" \"), \"{:<10} {:1} {:<10}\".format(  \"Leader\",'|', \"Follower\"  ))\n",
        "print( \"{:<15}\".format(\"Mod-1 DOBSS\")    ,\"{:<10} {:1} {:<10}\".format(  round(v2,2),'|',round(f2,2)))\n",
        "\n",
        "\n",
        "print(\"---------------------------------------------\\n\")\n",
        "\n",
        "print(\"Mod-2 DOBSS\")\n",
        "print(  \"{:<15}\".format(\" \"), \"{:<10} {:1} {:<10}\".format(  \"Leader\",'|', \"Follower\"  ))\n",
        "v3,f3,Z = optimal_strategy2(R,C,p,show=False,K=0.1,L=1.1,solver=0,lp=0)\n",
        "print( \"{:<15}\".format(\"K=0.1,L=1.1\")    ,\"{:<10} {:1} {:<10}\".format(  round(v3,2),'|',round(f3,2)))\n",
        "\n",
        "v3,f3,Z = optimal_strategy2(R,C,p,show=False,K=0.5,L=1.1,solver=0,lp=0)\n",
        "print( \"{:<15}\".format(\"K=0.5,L=1.1\")    ,\"{:<10} {:1} {:<10}\".format(  round(v3,2),'|',round(f3,2)))\n",
        "\n",
        "v3,f3,Z = optimal_strategy2(R,C,p,show=False,K=0.9,L=1.1,solver=0,lp=0)\n",
        "print( \"{:<15}\".format(\"K=0.9,L=1.1\")    ,\"{:<10} {:1} {:<10}\".format(  round(v3,2),'|',round(f3,2)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olOs2G1Dq3Ln",
        "outputId": "f57c06de-bda9-4970-a3d2-6be82230319f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------\n",
            "\n",
            "Original DOBSS\n",
            "                Leader     | Follower  \n",
            "Original DOBSS  1.0        | 1.0       \n",
            "---------------------------------------------\n",
            "\n",
            "Mod-1 DOBSS\n",
            "                Leader     | Follower  \n",
            "Mod-1 DOBSS     1.0        | 1.0       \n",
            "---------------------------------------------\n",
            "\n",
            "Mod-2 DOBSS\n",
            "                Leader     | Follower  \n",
            "K=0.1,L=1.1     0.1        | 1.0       \n",
            "K=0.5,L=1.1     0.5        | 1.0       \n",
            "K=0.9,L=1.1     0.9        | 1.0       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Endnote\n",
        "\n",
        "These two examples were chosen for simplification of the problem and easier understanding. The algorithm works in line with the expectations of the given inputs.\n",
        "\n",
        "The cases were taken individually for checking the behaviour of the output strategies with respect to individual parameters as suitable examples also are hard to construct that can give us intuitively understandable changes in the output strategies when both parameters are altered.\n",
        "\n",
        "Except for a few precision errors, no other error was encountered and the output strategies are according to our expectations from the algorithm."
      ],
      "metadata": {
        "id": "hd-tm-nQ3kzn"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "VKbOB7nB7tyk",
        "j4lhIBpNC7Br",
        "DMEapV9l8hYP"
      ],
      "name": "DOBSS testing 3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}